<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Needle Segmentation For Real-time Guidance">
  <meta name="keywords" content="Diffusion, zero-shot, video segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Needle Segmentation For Real-time Guidance</title>

   <!-- ––––––––––––––––––––––––––         Global site tag (gtag.js) - Google Analytics         –––––––––––––––––––––––––– -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

<!-- ––––––––––––––––––––––––––––––––––––––––––––––––––         fonts         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">


<!-- ––––––––––––––––––––––––––––––––––––––––––––––––––         CSS         –––––––––––––––––––––––––––––––––––––––––––––––––– -->      
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/style.css">


<!-- ––––––––––––––––––––––––––––––––––––––––––––––––––         favicon         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" href="./static/images/favicon.svg">

<!-- ––––––––––––––––––––––––––––––––––––––––––––––––––         JS         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<!-- ––––––––––––––––––––––––––––––––––––––––––––––––––         Body         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Needle Segmentation For Real-time Guidance of Minimally Invasive Procedures Using Handheld 2D Ultrasound Systems</h1>
          <!-- <h1 style="font-size:2em; " class="title is-1 publication">TechRxiv</h1> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Paul Okwija Mugume<sup>1</sup>,</span>
            <span class="author-block">
              Joanitta Nabacwa<sup>1</sup>,</span>
            <span class="author-block">
              Sylvia Imanirakiza<sup>1</sup>,
            </span>
            <span class="author-block">
              Alvin Bagetuuma Kimbowa<sup>1</sup>,
            </span>
            <span class="author-block">
              Cosmas Mwikirize<sup>1</sup>,
            </span>
            <span class="author-block">
              Ilker Hacihaliloglu<sup>2</sup>,
            </span>
            <span class="author-block">
              Andrew Katumba<sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Makerere University,</span>
            <span class="author-block"><sup>2</sup>University of British Columbia</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">

              <span class="link-block">
                <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.21234107.v1"
                   class="external-link button is-normal is-rounded is-dark">
                  <!-- <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span> -->
                  <span>TechRxiv</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/QianWangX/VidSeg_diffusion"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>


          </div>
        </div>
      </div>
    </div>
  </div>
</section>


 <!-- ––––––––––––––––––––––––––––––––––––––––––––––––––         Videos         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/50_9mZFBNGzmok.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/183_8Rpdn-7CEGs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/231_-_w6ZFauJBI.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/2097_HVti7xTm2ow.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/23_XmN5TD3AjMY.mp4"
                    type="video/mp4">
          </video>
        </div>


        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/1715_L8nqlt2mrNg.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/1096_atkIaj9LDYg.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/101_gx9PZZuwvoI.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/127_-hIVCYO4C90.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/437_-bUZU7-Mbjs.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/958__CDGCdwmlr0.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/1184__Ij5JaEIcPc.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/1203_gVvsmIrMHT4.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/1223_xD8VN2r_h2s.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/1229_92gCzJBNLcI.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/1356_ISS4MOFdZJo.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/1931_LaS9diS8990.mp4"
                    type="video/mp4">
          </video>
        </div>


      </div>
      <div class="content has-text-justified">
        <p>
          From left to right, we show the input video from <i>VSPW</i> dataset and the segmentation masks generated by EmerDiff (SD), <b>Ours (SVD)</b> and <b>Ours (SD)</b>, respectively.
        </p>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <!-- <p>We propose a novel machine learning based method for <b>real-time needle segmentation</b> in handheld 2D ultrasound systems.
          </p> -->
          <h2 class="title is-3">Background</h2>
          <p>
            Accurate needle placement is crucial during minimally invasive procedures such as biopsies, regional anaesthesia and fluid aspiration. 
            2D Ultrasound is widely used for needle guidance during such procedures, however, it has a limited field-of-view and poor needle visibility for steep insertion angles.
            
        </p>
        

        <h2 class="title is-3">Method</h2>
        <p>In this work, we propose a novel machine learning (ML)-based method for real-time needle segmentation in handheld 2D ultrasound systems. 
            The proposed method involves a fast and simple annotation technique allowing for the labelling of large datasets. It then utilizes the U-Net architecture which is
            modified to allow for easy integration into a handheld ultrasound system. Two datasets were used in this work, one consisting
            of B-mode ultrasound videos obtained from human tissue and the other consisting of videos and frames from chicken, porcine
            and bovine tissue. The model is trained on 1262 frames and evaluated on 209 frames.</p>
        <div class="content has-text-justified">
          <img src="./static/images/Clarius API.png" alt="Main workflow" style="width:100%">
          <figcaption>Main work flow after integration with Clarius API.Using the API, we stream images from the probe, 
            make and overlay the predictions on them before they are displayed on the GUI. 
          </figcaption>
        </div>


        <h2 class="title is-3">Results</h2>
        <p> This approach achieves an Intersection Over Union (IoU) of 0.75 and a dice coefficient of 0.851 on frames obtained from human tissue. The model is integrated
            into the processing pipeline of a portable ultrasound system and achieves an overall processing speed of about 8 frames per second.
            The proposed approach outperforms state-of-the-art methods for needle segmentation while achieving real-time integration.
            This work is a step forward towards real-time needle guidance using machine learning-based algorithms in handheld ultrasound
            systems.</p>

        </div>    
        <div class="content has-text-justified">
            <img src="./static/images/pred_1.png" alt="Sample predictions" style="width:100%">
            <!-- <figcaption>Sample predictions made 
            </figcaption> -->
          </div>


        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="70%">
            <source src="./static/videos/pc_1_3_1.mp4"
                    type="video/mp4">
          </video></div>
          <!-- <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/ph_1_3_1.mp4"
                    type="video/mp4">
          </video> -->
          <!--
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/frankfurt_000000_005879_leftImg8bit.mp4"
                    type="video/mp4">
          </video>
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/frankfurt_000000_006570_leftImg8bit.mp4"
                    type="video/mp4">
          </video>
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/frankfurt_000001_005684_leftImg8bit.mp4"
                    type="video/mp4">
          </video>
          <p>From left to right, we show the input video from <i>Cityscapes</i> dataset and the segmentation masks generated by EmerDiff (SD), <b>Ours (SVD)</b> and <b>Ours (SD)</b>, respectively.</p>
          <br>
          <br>
          <video poster="" id="fullbody" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/camvid.mp4"
                    type="video/mp4">
          </video>
        </div>
        <p>From left to right, we show the input video from <i>CamVid</i> dataset and the segmentation masks generated by EmerDiff (SD), <b>Ours (SVD)</b> and <b>Ours (SD)</b>, respectively.</p>
      </div>
      </div>
    </div> -->

    <!-- Citation -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h5>Citation</h5>
        <pre style="margin:0"><code>@article{mugume2022nseg,
title={Needle Segmentation For Real-time Guidance of Minimally Invasive 
Procedures Using Handheld 2D Ultrasound Systems.}, 
authors={Paul O Mugume, Alvin B Kimbowa, Sylvia Imanirakiza,
Cosmas Mwikirize, Ilker Hacihaliloglu, and Andrew Katumba},
journal = {TechRxiv}, year={October 05, 2022}
        }</code></pre>
      </div></div>

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This website is licensed under a <a rel="license"
                                                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>
              <p>
                We thank <a
                  href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> to provide the source code of the template.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>


</body>
</html>
